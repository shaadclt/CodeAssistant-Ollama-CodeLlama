# Code Assistant with Ollama and CodeLlama

This project provides a user-friendly Gradio interface that enables you to interact with the custom model based on CodeLlama model from Ollama, an open-source large language model platform. Simply enter your prompt in the textbox, and custom model will generate code based on your input.

## Features:

- Leverages Gradio for a user-friendly interactive experience.
- Integrates with the CodeLlama model from Ollama (https://ollama.com/), a free and open-source large language model platform.


## Installation:

1. Clone this repository:

```bash
git clone https://github.com/shaadclt/CodeAssistant-Ollama-CodeLlama.git
```

2. Install dependencies:

```Bash
cd CodeAssistant-Ollama-CodeLlama
pip install -r requirements.txt
```

## Usage:

1. Install Ollama:
2. Download the CodeLlama Model:
3. Create modelfile
4. Create custom model using Ollama
5. Run the custom model.
6. Start the Gradio Interface:
```bash
python app.py
```
7. Open **http://127.0.0.1:7860** in your web browser.
8. Enter your prompt in the textbox and click "Submit" to generate code based on your input.


## Contributing:

We welcome contributions to this project! Feel free to fork the repository, make your changes, and submit a pull request.

## License:

This project is licensed under the MIT License.

