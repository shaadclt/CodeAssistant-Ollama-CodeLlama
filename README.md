# Code Assistant with Ollama and CodeLlama

This project provides a user-friendly Gradio interface that enables you to interact with the CodeLlama model from Ollama, an open-source large language model platform. Simply enter your prompt in the textbox, and CodeLlama will generate code based on your input.

## Features:

- Leverages Gradio for a user-friendly interactive experience.
- Integrates with the CodeLlama model from Ollama (https://ollama.com/), a free and open-source large language model platform.


## Installation:

1. Clone this repository:

```bash
git clone https://github.com/your-username/gradio-code-generation.git
```

2. Install dependencies:

```Bash
cd CodeAssistant-Ollama-CodeLlama
pip install -r requirements.txt
```

## Usage:

1. Install Ollama:

If you haven't already, follow the installation instructions for Ollama from their website: https://ollama.com/

2. Download the CodeLlama Model:

Use Ollama to download the CodeLlama model and follow the appropriate instructions for your system: https://ollama.com/ for details on downloading models.

3. Create modelfile

4. Create custom model using Ollama

5. Run the custom model.

6. Start the Gradio Interface:

```bash
python app.py
```

7. Open **http://127.0.0.1:7860** in your web browser.

8. Enter your prompt in the textbox and click "Submit" to generate code based on your input.


## Contributing:

We welcome contributions to this project! Feel free to fork the repository, make your changes, and submit a pull request.

## License:

This project is licensed under the MIT License.

